---
title: "Task 4"
author: "Hannes Guth"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#  {.tabset}

```{r, message=FALSE, warning=FALSE}
library(fpp3) # package with different function, amongst other add_column()
library(ggplot2) # package for creating plots
library(data.table) # package to handle data tables
library(dplyr) # package to use the pipe operator
library(knitr) # package to present tables
library(geomtextpath) # package to add labels in ggplots
```

## a.

#### Set the two Holt's model with additive ETS(A,A,N).

The data is being loaded as a first step and then transformed into a
tsibble object that is the following.

```{r, message=FALSE, warning=FALSE}
books = data.table(read.csv2("books.csv", sep=";")) # read the data set and convert it to a data table
books = add_column(books, time = seq(1,30,1), .before = 1) # add a column for numerating from 1:30 as a time index
books_tsibble = as_tsibble(books,
                           index = time) # create a new tsibble object from the data table
kable(head(books_tsibble, 6)) # present the head of the table
```

In this paragraph, the two models are established. They shall have an
additive error, an additive trend and no seasonality.

```{r, message=FALSE, warning=FALSE, class.source = "fold-show"}
# create a model for the hardcover, using the previously created tsibble object
holt_hardcover = books_tsibble %>%
  model(
    `Holt_Hardcover` = ETS(Hardcover ~ error("A") + trend("A") + season("N"))
  )

# create a model for the paperback, using the previously created tsibble object
holt_paperback = books_tsibble %>%
  model(
    `Holt_Paperback` = ETS(Paperback ~ error("A") + trend("A") + season("N"))
  )
```

Showing the report of the models give amongst others information about
the variance of the models that will be needed in the upcoming steps.

```{r, message=FALSE, warning=FALSE}
report(holt_hardcover) # show the report of the hardcover model
report(holt_paperback) # show the report of the paperback model
```

From this point, one calculates the standard deviations of the
respective models.

```{r, message=FALSE, warning=FALSE}
# calculate the standard deviations from the retrieved variances
std_H = as.integer(sqrt(853.2586))
std_P = as.integer(sqrt(1118.663))

# show the standard deviations
paste("Standard deviation hardcover:", std_H)
paste("Standard deviation paperback:", std_P)
```

The levels and trends of the models are taken from the components and
have the following values.

```{r, message=FALSE, warning=FALSE}
# take the last observation of the components of the 2 models at level and trend
LH_30 = components(holt_hardcover)[31,4]
TH_30 = components(holt_hardcover)[31,5]

LP_30 = components(holt_paperback)[31,4]
TP_30 = components(holt_paperback)[31,5]

# show the values
paste("Level hardover at period 30:", round(LH_30))
paste("Trend hardcover at period 30:", round(TH_30, 2))
paste("Level paperback at period 30:", round(LP_30))
paste("Trend paperback at period 30:", round(TP_30, 2))
```

The hardcover books have a bigger trend and also a higher value in the
30th period than the ones with a paperback.

## b.

#### Simulate 2 sets of 1000 random normal variables associated with each model.

As a first step, 1000 random values with the properties (mean and
standard deviation) of the models will be created.

```{r, message=FALSE, warning=FALSE}
set.seed(1) # for reproducibility

# generate 1000 random samples with the respective mean and standard deviation of the models
randomH = rnorm(n = 1000, as.integer(LH_30 + TH_30), std_H)

set.seed(1) # for reproducibility
randomP = rnorm(n = 1000, as.integer(LP_30 + TP_30), std_P)
```

As a second step, a new data table will be created to store the
previously obtained results.

```{r, message=FALSE, warning=FALSE}
# generate a table to store the results
random_var = data.table("Number" = seq(1,1000,1),
                        "randomH" = randomH,
                        "randomP" = randomP)

# show the head of the table
kable(head(random_var, 6))
```

To get a better impression of the distribution of the generated values
of the two models, they will be presented graphically.

```{r, message=FALSE, warning=FALSE}
options(scipen=999) # avoid scientific notation

ggplot(random_var) + # create new ggplot with random_var as input data
  geom_bar(stat = "bin", aes(x = randomH, fill = "Hardcover", color = "Hardcover"), alpha = 0.5) + # one set of bars for Hardcover, alpha for transparency
  geom_bar(stat = "bin", aes(x = randomP, fill = "Paperback", color = "Paperback"),  alpha = 0.5) + # one set of bars for Paperback, alpha for transparency
  scale_color_manual(values = c("Hardcover" = "black",
                                "Paperback" = "black")) + # set the color for the borders
  scale_fill_manual(values = c("Hardcover" = "red",
                                "Paperback" = "yellow")) + # set the color for the filling
  theme(legend.title = element_blank(),
        panel.background = element_rect(fill = "white", colour = "black"),
        panel.grid.major = element_line(colour = "white", size = 0.5)) + # remove the legend title and set a white background
  labs(title = "Distribution of the simulations",
       x = "Sales",
       y = "Frequency") + # edit the labels
  guides(color = "none") + # remove the legend for the borders
  geom_textvline(xintercept = as.integer(LH_30),
                 label = paste(as.integer(LH_30), "(Mean hardcover)"),
                 color = "black",
                 offset = -0.2) + # label the mean of the hardcover distribution
    geom_textvline(xintercept = as.integer(LP_30),
                 label = paste(as.integer(LP_30), "(Mean paperback)"),
                 color = "black",
                 offset = -0.2)  # label the mean of the paperback distribution
```

\
As expected, the distribution of the paperback has a higher mean than
the one of the hardcover and is therefore shifted to the right, compared
to the one representing the hardcover distribution. By definition, both
follow the normal distribution.

## c.

#### Estimate the probability P(yt+1 \> wt+1) for the corresponding proportion.

To calculate the percentage of the cases when the hardcover sales are
smaller than the paperback sales, one can compare the single
observations of the two distributions pairwise and then average over
them.

```{r Calculate percentage of H > P, message=FALSE, warning=FALSE}
round(mean(outer(random_var$randomP, random_var$randomH, ">")), 4) * 100 # compare the observations of the two simulations pairwise and average over them
```

The estimated percentage of paperback sales being bigger than hardcover
sales is 18.29 %.

## d.

#### Under which assumptions the computation on the point c. before can be performed?

It is necessary that the normality assumption holds and that the data in between one distribution and between the two distributions were created randomly and independent from each other. There needs to be a constant variance and the errors should be independent from each other. These assumptions are met.

## References

#### Packages

Hyndman R (2023). *fpp3: Data for "Forecasting: Principles and Practice"
(3rd Edition)*. R package version 0.5,
<https://CRAN.R-project.org/package=fpp3>.

H. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag
New York, 2016.

Dowle M, Srinivasan A (2021). *data.table: Extension of `data.frame`*. R
package version 1.14.2, <https://CRAN.R-project.org/package=data.table>.

Wickham H, François R, Henry L, Müller K (2022). *dplyr: A Grammar of
Data Manipulation*. R package version 1.0.10,
<https://CRAN.R-project.org/package=dplyr>.

Yihui Xie (2022). knitr: A General-Purpose Package for Dynamic Report
Generation in R. R package version 1.40.

Yihui Xie (2015) Dynamic Documents with R and knitr. 2nd edition.
Chapman and Hall/CRC. ISBN 978-1498716963

Yihui Xie (2014) knitr: A Comprehensive Tool for Reproducible Research
in R. In Victoria Stodden, Friedrich Leisch and Roger D. Peng, editors,
Implementing Reproducible Computational Research. Chapman and Hall/CRC.
ISBN 978-1466561595

Cameron A, van den Brand T (2022). *geomtextpath: Curved Text in
'ggplot2'*. R package version 0.1.1,
<https://CRAN.R-project.org/package=geomtextpath>.
